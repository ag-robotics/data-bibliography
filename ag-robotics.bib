
@misc{dias_data_2018,
	title = {Data from: {Multi}-species fruit flower detection using a refined semantic segmentation network},
	shorttitle = {Data from},
	url = {https://data.nal.usda.gov/dataset/data-multi-species-fruit-flower-detection-using-refined-semantic-segmentation-network},
	language = {en},
	urldate = {2019-04-28},
	publisher = {Ag Data Commons},
	author = {Dias, Philipe A. and Tabb, Amy and Medeiros, Henry},
	year = {2018},
	doi = {10.15482/usda.adc/1423466},
	note = {type: dataset},
	keywords = {flower, fruit, orchard}
}

@article{pire_rosario_2019,
	title = {The {Rosario} dataset: {Multisensor} data for localization and mapping in agricultural environments},
	issn = {0278-3649},
	shorttitle = {The {Rosario} dataset},
	url = {https://doi.org/10.1177/0278364919841437},
	doi = {10.1177/0278364919841437},
	abstract = {In this paper we present the Rosario dataset, a collection of sensor data for autonomous mobile robotics in agricultural scenes. The dataset is motivated by the lack of realistic sensor readings gathered by a mobile robot in such environments. It consists of six sequences recorded in soybean fields showing real and challenging cases: highly repetitive scenes, reflection, and burned images caused by direct sunlight and rough terrain among others. The dataset was conceived in order to provide a benchmark and contribute to the agricultural simultaneous localization and mapping (SLAM)/odometry and sensor fusion research. It contains synchronized readings of several sensors: wheel odometry, inertial measurement unit (IMU), stereo camera, and a Global Positioning System real-time kinematics (GPS-RTK) system. The dataset is publicly available from http://www.cifasis-conicet.gov.ar/robot/.},
	language = {en},
	urldate = {2019-04-28},
	journal = {The International Journal of Robotics Research},
	author = {Pire, Taihú and Mujica, Martín and Civera, Javier and Kofman, Ernesto},
	month = apr,
	year = {2019},
	note = {Dataset URL: http://www.cifasis-conicet.gov.ar/robot/doku.php},
	pages = {0278364919841437},
	keywords = {mobile robots, odometry, IMU, GPS-RTK}
}

@misc{pezzementi_zachary_a._national_2018,
	title = {The {National} {Robotics} {Engineering} {Center} {Agricultural} {Person}-{Detection} {Dataset}},
	url = {https://data.nal.usda.gov/dataset/national-robotics-engineering-center-agricultural-person-detection-dataset},
	abstract = {Person detection from vehicles has made rapid progress recently with the advent of multiple high-quality datasets of urban and highway driving, yet no large-scale benchmark is available for the same problem in off-road or agricultural environments. Here we present the National Robotics Engineering Center (NREC) Agricultural Person-Detection Dataset to spur research in these environments. It consists of labeled stereo video of people in orange and apple orchards taken from two perception platforms (a tractor and a pickup truck), along with vehicle position data from Real Time Kinetic (RTK) GPS. We define a benchmark on part of the dataset that combines a total of 76k labeled person images and 19k sampled person-free images. The dataset highlights several key challenges of the domain, including varying environment, substantial occlusion by vegetation, people in motion and in nonstandard poses, and people seen from a variety of distances; metadata are included to allow targeted evaluation of each of these effects.},
	language = {en},
	urldate = {2019-03-27},
	author = {{Pezzementi, Zachary A.} and {Tabor, Trenton} and {Hu, Peiyun} and {Chang, Jonathan K.} and {Ramanan, Deva} and {Wellington, Carl K.} and {Wisely Babu, Benzun P.} and {Herman, Herman}},
	year = {2018},
	keywords = {stereo, RTK-GPS, person detection}
}
